# Governance, Risk & Compliance in AI

## What is GRC?

Governance, Risk and Compliance (GRC) is a system used to structure governance, risk management and regulatory compliance.

It unifies an org's approach to risk management and compliance. 

## Typical GRC

- Corporate strategy 
- HR
- Finance
- Enviro and social
- IT and Cyber security

## GRC and AI

AI Model Governance

- Explaining decisions, identifying AI

AI Risk Management

- Data breaches, bias etc

AI Compliance

- Adhering to standards

### Why GRC? 

AI is opaque, autonomous, scalable and represents potential ethical concerns that requires GRC oversight.

## Key Existing Frameworks

### ISO42001

Information Technology - Artificial Intelligence - Management System

It is actually certifiable!

Management system for establishing minimum acceptable standards to develop and deploy AI Systems.

### OECD AI Principals

Five principals of trustworthy AI:

- Inclusive growth, sustainable Development and Wellbeing
- Human centred values and fairness
- Transparency and explainability
- Robustness, security and safety
- Accountability


### NIST AI Risk Management Framework

National Institute of Standards and Technology

Voluntary standards, designed to improve the ability to incorporate trustworthiness considerations into the design, development use and evaluation of AI products.

Pushes trustworthiness use of AI, platform neutral, intended to be incorporated into other standards. Supplimentary and not replace.

Follows govern, map, measure, anage approach.

### European Union Artificial Intelligence Act

First piece of comprehensive AI Regulation.

Risk based approach to regulate the entire lifecycle.

Regulates players in the market. Includes those that are outside of the EU, but play in that market. 

Categorises systems into four classes. Prohibited AI Systems, High Risk AI Systems, Low Risk AI System, No Risk AI

Prohibited is bad things (subliminal messaging / exploit vulns), high risk is scary things (police / health), low risk is chatbots (user must be informed), no risk (no requirements / AI in games or spam filters)

### Corporate Misc

## Aus Standards

### Voluntary AI Safety Standards

Announced in 2024, designed to ensure that Aus players use Ai in a safeway

10 different guardrails:

1. Implement accountablity and governance for AI
2. Implement risk management process and mitigations for AI risk
3. Protect AI systems and manage data, data quality and provenance
4. Test use of AI, monitor performance and monitor once deployed
5. Enable human oversight, control and intervention in AI systems
6. Inform end users of AI, AI decisions and use of AI
7. Establish processes for people impacted by AI use or outcomes
8. Be transparent with other businesses in use and management of AI systems
9. Keep and maintain AI docs to allow for third party management and oversight
10. Engage with stateholders and evaluate needs, circumstance and any safety implications

### OAIC Guidance

Provides guidance for:

- Privacy for developing and training models
- Privacy for when using commercially available AI products

Such as:

- Management of training data and other inputs (PII)
- Ensuing you are not infringing on other rights by use of data. e.g. collecting PII and then using for training

Commercial concerns:

- Privacy policies are adhered to, since the models are probably third parties

## Which Rules?

Probably use a combination. They are broadly designed to work together. ISO42001 is a certifiable system to ensure that you can adhere to the OIAC or Aus Gov standards, which will let you comply with the EU act.
